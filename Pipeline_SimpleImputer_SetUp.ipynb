{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHJaJ7X+ExTLOfbBsTqOuH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhangling297/Substance-Use/blob/master/Pipeline_SimpleImputer_SetUp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxAqnG4Xxp1x"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assume df is your DataFrame and 'target_column' is your target\n",
        "X = zip_df.drop('ZIPCODE', axis=1)\n",
        "y = zip_df['ZIPCODE']\n",
        "\n",
        "# Identify column types\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Preprocessing for numeric features\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean'))\n",
        "])\n",
        "\n",
        "# Preprocessing for categorical features\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine preprocessing\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "# Full pipeline\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit and predict\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_test_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"=== Model Performance ===\")\n",
        "print(f\"Test R2 Score: {r2_score(y_test, y_test_pred):.4f}\")\n",
        "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred)):.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_validate, train_test_split\n",
        "\n",
        "# Split your data (assuming df is your DataFrame)\n",
        "X = zip_df.drop('ZIPCODE', axis=1)\n",
        "y = zip_df['ZIPCODE']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Identify column types\n",
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Preprocessing transformers\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean'))\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine preprocessing\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numeric_features),\n",
        "    ('cat', categorical_transformer, categorical_features)\n",
        "])\n",
        "\n",
        "# Full pipeline\n",
        "linear_regression_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Define metrics\n",
        "scoring = [\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\", \"r2\"]\n",
        "\n",
        "# Cross-validation with error handling\n",
        "cv_scores_lr = cross_validate(\n",
        "    linear_regression_pipeline,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring=scoring,\n",
        "    return_train_score=True,\n",
        "    error_score='raise'  # helps debug errors instead of suppressing them\n",
        ")\n",
        "\n",
        "# Plot model evaluation results\n",
        "plt.figure(figsize=(6, 2))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.bar(\n",
        "    [0, 1],\n",
        "    [-np.mean(cv_scores_lr[\"train_neg_mean_absolute_error\"]), -np.mean(cv_scores_lr[\"test_neg_mean_absolute_error\"])],\n",
        "    yerr=[np.std(cv_scores_lr[\"train_neg_mean_absolute_error\"]), np.std(cv_scores_lr[\"test_neg_mean_absolute_error\"])]\n",
        ")\n",
        "plt.xticks([0, 1], [\"Train\", \"Test\"])\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.ylim(0, 60)  # corrected from plt.ylim[0,60] to plt.ylim(0, 60)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.bar(\n",
        "    [0, 1],\n",
        "    [-np.mean(cv_scores_lr[\"train_neg_mean_absolute_error\"]), -np.mean(cv_scores_lr[\"test_neg_mean_absolute_error\"])],\n",
        "    yerr=[np.std(cv_scores_lr[\"train_neg_mean_absolute_error\"]), np.std(cv_scores_lr[\"test_neg_mean_absolute_error\"])]\n",
        ")\n",
        "plt.xticks([0, 1], [\"Train\", \"Test\"])\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.ylim(0, 60)  # corrected from plt.ylim[0,60] to plt.ylim(0, 60)\n",
        "\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.bar(\n",
        "    [0, 1],\n",
        "    [np.mean(cv_scores_lr[\"train_r2\"]), np.mean(cv_scores_lr[\"test_r2\"])],\n",
        "    yerr=[np.std(cv_scores_lr[\"train_r2\"]), np.std(cv_scores_lr[\"test_r2\"])]\n",
        ")\n",
        "plt.xticks([0, 1], [\"Train\", \"Test\"])\n",
        "plt.ylabel(\"$R^2$\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "\n",
        "# define pipelines\n",
        "pipeline_en = make_pipeline(\n",
        "    ElasticNet()\n",
        ")\n",
        "\n",
        "pipeline_rfr = make_pipeline(\n",
        "    RandomForestRegressor()\n",
        ")\n",
        "\n",
        "pipeline_gbr = make_pipeline(\n",
        "    GradientBoostingRegressor()\n",
        ")\n",
        "\n",
        "# perform cross-validation\n",
        "\n",
        "cv_en = cross_validate(\n",
        "        pipeline_en,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cv=5,\n",
        "        scoring=scoring,\n",
        "        return_train_score=True\n",
        "    )\n",
        "pipeline_gbr = male_pipeline(\n",
        "    GradientBoostingRegressor()\n",
        ")\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_en = cross_validate(\n",
        "        pipeline_en,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cv=5,\n",
        "        scoring=scoring,\n",
        "        return_train_score=True\n",
        ")\n",
        "\n",
        "cv_rfr = cross_validate(\n",
        "        pipeline_rfr,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cv=5,\n",
        "        scoring=scoring,\n",
        "        return_train_score=True\n",
        "    )\n",
        "\n",
        "cv_gbr = cross_validate(\n",
        "        pipeline_gbr,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cv=5,\n",
        "        scoring=scoring,\n",
        "        return_train_score=True\n",
        "    )\n",
        "print(\"Other three models trained!\")\n"
      ],
      "metadata": {
        "id": "oYocncSAkARK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}